{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFA_cq0WEBWS"
   },
   "source": [
    "## **Model Fine-tuning** (Notebook sourced from translation notebook [here](https://huggingface.co/docs/transformers/notebooks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6zcdt7BpLJE"
   },
   "source": [
    "Enable logging with Weights and Biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# del model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jcuv1RmQpEt7"
   },
   "outputs": [],
   "source": [
    "wb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P0kUE65nK_9p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "work_dir = os.getcwd()\n",
    "if work_dir == '/content':\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  os.chdir('drive/MyDrive/github_repos/XLdefgen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "If running this on Colab, uncomment the following cell to install requisite packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MOsHUjgdIrIW"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets transformers sacrebleu sentencepiece wandb\n",
    "# !apt install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EmnzArcYCFS8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbrandonwilde\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=XLdefgen\n"
     ]
    }
   ],
   "source": [
    "if wb:\n",
    "  import wandb\n",
    "  wandb.login()\n",
    "  %env WANDB_PROJECT=XLdefgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JL5wd9Z4u1U"
   },
   "source": [
    "If storing model on HF Model Hub, uncomment the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pIymjpij4u1V"
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFASsisvIrIb"
   },
   "source": [
    "A script version of this notebook to fine-tune the model in a distributed fashion using multiple GPUs or TPUs is available [here](https://github.com/huggingface/transformers/tree/master/examples/seq2seq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "Specify model checkpoint to load (from HF Model Hub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UlraLg9K4u1Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\brand\\\\Documents\\\\Projects\\\\XLdefgen'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"google/mt5-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "### import datasets\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"codwoe_data.csv\"\n",
    "\n",
    "class csvDataset(Dataset):\n",
    "\n",
    "    def __init__(self,file_name):\n",
    "        self.data_df = pd.read_csv(file_name)\n",
    "        self.data_dict = data_df.to_dict(orient='index')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        import numbers\n",
    "        if isinstance(idx, numbers.Integral):  # item is an integer\n",
    "            idx = [idx]\n",
    "        elif isinstance(idx, slice):  # item is a slice\n",
    "            idx = list(range(idx.start or 0, idx.stop or len(self), idx.step or 1))\n",
    "        else:  # invalid index type\n",
    "            raise TypeError('{cls} indices must be integers or slices, not {idx}'.format(\n",
    "                cls=type(self).__name__,\n",
    "                idx=type(idx).__name__,\n",
    "            ))\n",
    "\n",
    "        return [self.data_dict[i] for i in idx]\n",
    "\n",
    "codwoe_data = csvDataset(data_path)\n",
    "\n",
    "# raw_datasets = datasets.load_from_disk(\"de-en_wmt16_tokd\")\n",
    "# raw_datasets = load_dataset(\"wmt16\", \"de-en\")\n",
    "\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'insurrectionalism',\n",
       "  'pos': 'noun',\n",
       "  'gloss': 'The belief that insurrection is the best way to achieve a communist or socialist revolution .',\n",
       "  'example': \"Those already wary of the party 's electoral maneuvers in 1919 further resented the Socialists ' calls , after the May 1920 strike failure , to abandon revolutionary insurrectionalism and place all hopes in `` le bulletin rouge '' .\"},\n",
       " {'word': 'ofay',\n",
       "  'pos': 'noun',\n",
       "  'gloss': 'A white person .',\n",
       "  'example': 'You get outa my alley , Lucas -- and take that ofay with you , hear ?'}]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['validation']['translation'][:2]\n",
    "codwoe_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "To get a sense of what the data looks like, the following function shows some examples picked randomly from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# import random\n",
    "# import pandas as pd\n",
    "# from IPython.display import display, HTML\n",
    "\n",
    "# def show_random_elements(dataset, num_examples=5):\n",
    "#     assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "#     picks = []\n",
    "#     for _ in range(num_examples):\n",
    "#         pick = random.randint(0, len(dataset)-1)\n",
    "#         while pick in picks:\n",
    "#             pick = random.randint(0, len(dataset)-1)\n",
    "#         picks.append(pick)\n",
    "    \n",
    "#     df = pd.DataFrame(dataset[picks])\n",
    "#     for column, typ in dataset.features.items():\n",
    "#         if isinstance(typ, datasets.ClassLabel):\n",
    "#             df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "#     display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "SZy5tRB_IrI7"
   },
   "outputs": [],
   "source": [
    "# show_random_elements(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAWdqcUBIrJC"
   },
   "source": [
    "Demonstration of the metric in use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6XN1Rq0aIrJC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0,\n",
       " 'counts': [4, 2, 0, 0],\n",
       " 'totals': [4, 2, 0, 0],\n",
       " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = [\"hello there\", \"general kenobi\"]\n",
    "fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "Model-specific tokenizer adaptations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zqn3ZeBl4u1k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs will include prefix!\n"
     ]
    }
   ],
   "source": [
    "if \"t5\" in model_checkpoint:\n",
    "    prefix = \"translate German to English: \"\n",
    "    print(\"Inputs will include prefix!\")\n",
    "else:\n",
    "    prefix = \"\"\n",
    "    print(\"Inputs will not include prefix!\")\n",
    "\n",
    "if \"mbart\" in model_checkpoint:\n",
    "    tokenizer.src_lang = \"en-XX\"\n",
    "    tokenizer.tgt_lang = \"de-DE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzohepNVHEuL"
   },
   "source": [
    "Create preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"de\"\n",
    "target_lang = \"en\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1xBe3UiHTkp"
   },
   "source": [
    "Specify whether reduced dataset should be passed to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Sii3lf3ThnPM"
   },
   "outputs": [],
   "source": [
    "trim_datasets = True\n",
    "train_size = 10000\n",
    "eval_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8eOtIBLHgaB"
   },
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uAr_iWrLurIK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/wildeb1/.cache/huggingface/datasets/wmt16/de-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a/cache-4574fe47268cd3fd.arrow\n",
      "Loading cached shuffled indices for dataset at /home/wildeb1/.cache/huggingface/datasets/wmt16/de-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a/cache-bf1487bfb5cd2cad.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954cef349e4e4e1990f544f97d40c547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c76d66d3e542df9b601105cead9c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets trimmed and tokenized.\n"
     ]
    }
   ],
   "source": [
    "if trim_datasets:\n",
    "  small_train_dataset = raw_datasets[\"train\"].shuffle(seed=42).select(range(train_size))\n",
    "  small_eval_dataset = raw_datasets[\"validation\"].shuffle(seed=42).select(range(eval_size))\n",
    "  raw_datasets_trim = datasets.DatasetDict({'train': small_train_dataset, 'validation': small_eval_dataset})\n",
    "  tokenized_datasets = raw_datasets_trim.map(preprocess_function, batched=True)\n",
    "  print(\"Datasets trimmed and tokenized.\")\n",
    "else:\n",
    "  tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n",
    "  print(\"Raw datasets tokenized.\")\n",
    "\n",
    "del raw_datasets #to clear memory\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voWiw8C7IrJV"
   },
   "source": [
    "The results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). 🤗 Datasets warns you when it uses cached files, but you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Now that our data is ready, we can download the pretrained model and fine-tune it. Since our task is of the sequence-to-sequence kind, we use the `AutoModelForSeq2SeqLM` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TlqNaB8jIrJW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n",
    "\n",
    "\n",
    "# class MyTrainer(Trainer): #Subclass trainer to access \n",
    "#   def init(self, model,\n",
    "#            args = None,\n",
    "#            data_collator = None,\n",
    "#            train_dataset = None,\n",
    "#            eval_dataset = None,\n",
    "#            tokenizer = None,\n",
    "#            model_init = None,\n",
    "#            compute_metrics = None,\n",
    "#            callbacks = None,\n",
    "#            optimizers = (None,None)\n",
    "#            ):\n",
    "\n",
    "# super().__init__(model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init,\n",
    "#               compute_metrics, callbacks, optimizers) \n",
    "\n",
    "# def evaluate(\n",
    "# self,\n",
    "# train_dataset = None,\n",
    "# eval_dataset: Optional[Dataset] = None,\n",
    "# ignore_keys: Optional[List[str]] = None,\n",
    "# metric_key_prefix: str = “eval”,\n",
    "# ) → Dict[str, float]:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "Specify batch size and training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Bliy8zgjIrJY"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "if wb:\n",
    "  report = \"wandb\"\n",
    "else:\n",
    "  report = \"none\"\n",
    "train_k = int(train_size/1000)\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    # f\"drive/MyDrive/{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
    "    # f\"XLdefgen-{source_lang}-to-{target_lang}\",\n",
    "    f\"XLdefgen-trans-{source_lang}-to-{target_lang}-train{train_k}k-bat{batch_size}\", #output directory\n",
    "    evaluation_strategy = \"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2, #max num of checkpoints to keep\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,         #mixed precision (acceleration) - doesn't work well with t5 models\n",
    "    push_to_hub=False,  #push to HF Model Hub\n",
    "    report_to=report,   #for data logging\n",
    "    ignore_data_skip=False,   #if true and loading from checkpoint, this will start at beginning of dataset rather than where left off\n",
    "    load_best_model_at_end=False,\n",
    "    prediction_loss_only=False, #save space by not storing predictions for metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vtlfP4mLAtV"
   },
   "source": [
    "Add data collator to pad inputs and labels to max length for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-HycQdUC4u1o"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ylg71wOsLYgv"
   },
   "source": [
    "Post-processing and compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UmvbnJ9JIrJd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "    return result\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#   '''Example for logging multiple metrics'''\n",
    "#     metric1 = load_metric(\"precision\")\n",
    "#     metric2 = load_metric(\"recall\")\n",
    "    \n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     precision = metric1.compute(predictions=predictions, references=labels)[\"precision\"]\n",
    "#     recall = metric2.compute(predictions=predictions, references=labels)[\"recall\"]\n",
    "#     return {\"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "Instantiate Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "y3wZsCwxw0w2"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "import math\n",
    "class MyTrainer(Seq2SeqTrainer):\n",
    "  # Adapt Trainer to also log perplexity - this only works on trainer.evaluate() and not trainer.train()\n",
    "  def evaluate(\n",
    "        self,\n",
    "        eval_dataset: Optional[Dataset] = None,\n",
    "        ignore_keys: Optional[List[str]] = None,\n",
    "        metric_key_prefix: str = \"eval\",\n",
    "  ) -> Dict[str, float]:\n",
    "    output = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "    output['eval_perplexity'] = round(math.exp(output['eval_loss']),4)\n",
    "    return output\n",
    "  \n",
    "trainer = MyTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [],
   "source": [
    "# trainer = Seq2SeqTrainer(\n",
    "#     model,\n",
    "#     args,\n",
    "#     train_dataset=tokenized_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_datasets[\"validation\"],\n",
    "#     data_collator=data_collator,\n",
    "#     tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )\n",
    "\n",
    "# from typing import Optional, List, Dict\n",
    "# from torch.utils.data import Dataset\n",
    "# import time\n",
    "\n",
    "# class MyTrainer(Seq2SeqTrainer):\n",
    "  \n",
    "#   def evaluate(\n",
    "#         self,\n",
    "#         eval_dataset: Optional[Dataset] = None,\n",
    "#         ignore_keys: Optional[List[str]] = None,\n",
    "#         metric_key_prefix: str = \"eval\",\n",
    "#   ) -> Dict[str, float]:\n",
    "#         \"\"\"\n",
    "#         Run evaluation and returns metrics.\n",
    "#         The calling script will be responsible for providing a method to compute metrics, as they are task-dependent\n",
    "#         (pass it to the init `compute_metrics` argument).\n",
    "#         You can also subclass and override this method to inject custom behavior.\n",
    "#         Args:\n",
    "#             eval_dataset (`Dataset`, *optional*):\n",
    "#                 Pass a dataset if you wish to override `self.eval_dataset`. If it is an `datasets.Dataset`, columns not\n",
    "#                 accepted by the `model.forward()` method are automatically removed. It must implement the `__len__`\n",
    "#                 method.\n",
    "#             ignore_keys (`Lst[str]`, *optional*):\n",
    "#                 A list of keys in the output of your model (if it is a dictionary) that should be ignored when\n",
    "#                 gathering predictions.\n",
    "#             metric_key_prefix (`str`, *optional*, defaults to `\"eval\"`):\n",
    "#                 An optional prefix to be used as the metrics key prefix. For example the metrics \"bleu\" will be named\n",
    "#                 \"eval_bleu\" if the prefix is \"eval\" (default)\n",
    "#         Returns:\n",
    "#             A dictionary containing the evaluation loss and the potential metrics computed from the predictions. The\n",
    "#             dictionary also contains the epoch number which comes from the training state.\n",
    "#         \"\"\"\n",
    "#         # memory metrics - must set up as early as possible\n",
    "#         self._memory_tracker.start()\n",
    "\n",
    "#         eval_dataloader = self.get_eval_dataloader(eval_dataset)\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         eval_loop = self.prediction_loop if self.args.use_legacy_prediction_loop else self.evaluation_loop\n",
    "#         output = eval_loop(\n",
    "#             eval_dataloader,\n",
    "#             description=\"Evaluation\",\n",
    "#             # No point gathering the predictions if there are no metrics, otherwise we defer to\n",
    "#             # self.args.prediction_loss_only\n",
    "#             prediction_loss_only=True if self.compute_metrics is None else None,\n",
    "#             ignore_keys=ignore_keys,\n",
    "#             metric_key_prefix=metric_key_prefix,\n",
    "#         )\n",
    "\n",
    "#         print(\"output:\",output)\n",
    "#         print(\"output.metrics:\", output.metrics)\n",
    "\n",
    "#         total_batch_size = self.args.eval_batch_size * self.args.world_size\n",
    "#         output.metrics.update(\n",
    "#             speed_metrics(\n",
    "#                 metric_key_prefix,\n",
    "#                 start_time,\n",
    "#                 num_samples=output.num_samples,\n",
    "#                 num_steps=math.ceil(output.num_samples / total_batch_size),\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#         self.log(output.metrics)\n",
    "\n",
    "#         if DebugOption.TPU_METRICS_DEBUG in self.args.debug:\n",
    "#             # tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\n",
    "#             xm.master_print(met.metrics_report())\n",
    "\n",
    "#         self.control = self.callback_handler.on_evaluate(self.args, self.state, self.control, output.metrics)\n",
    "\n",
    "#         self._memory_tracker.stop_and_update_metrics(output.metrics)\n",
    "\n",
    "#         return output.metrics\n",
    "\n",
    "# trainer = MyTrainer(\n",
    "#     model,\n",
    "#     args,\n",
    "#     train_dataset=tokenized_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_datasets[\"validation\"],\n",
    "#     data_collator=data_collator,\n",
    "#     tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "Train/fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "z4xOvCQ3k1EY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 03:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/brandonwilde/XLdefgen/runs/3hxi99gk\" target=\"_blank\">XLdefgen-trans-de-to-en-train10k-bat2</a></strong> to <a href=\"https://wandb.ai/brandonwilde/XLdefgen\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 22.424962997436523,\n",
       " 'eval_bleu': 0.1892,\n",
       " 'eval_gen_len': 2.4,\n",
       " 'eval_runtime': 4.61,\n",
       " 'eval_samples_per_second': 21.692,\n",
       " 'eval_steps_per_second': 10.846,\n",
       " 'eval_perplexity': 5483245446.8795}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "uNx5pyRlIrJh",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-5000).\n",
      "The following columns in the training set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 10000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10000\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 1\n",
      "  Continuing training from global step 5000\n",
      "  Will skip the first 1 epochs then the first 0 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a66f51087942b5baaffd5017abe03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 34:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.384400</td>\n",
       "      <td>2.917070</td>\n",
       "      <td>2.173800</td>\n",
       "      <td>16.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.291500</td>\n",
       "      <td>2.898247</td>\n",
       "      <td>2.092200</td>\n",
       "      <td>16.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.257200</td>\n",
       "      <td>2.880438</td>\n",
       "      <td>2.596400</td>\n",
       "      <td>16.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.236500</td>\n",
       "      <td>2.861647</td>\n",
       "      <td>2.264900</td>\n",
       "      <td>16.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.172200</td>\n",
       "      <td>2.850832</td>\n",
       "      <td>2.079700</td>\n",
       "      <td>16.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.208500</td>\n",
       "      <td>2.841267</td>\n",
       "      <td>1.828200</td>\n",
       "      <td>16.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>4.181700</td>\n",
       "      <td>2.833421</td>\n",
       "      <td>1.885300</td>\n",
       "      <td>16.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.211200</td>\n",
       "      <td>2.829205</td>\n",
       "      <td>2.347600</td>\n",
       "      <td>16.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>4.107500</td>\n",
       "      <td>2.826155</td>\n",
       "      <td>2.387100</td>\n",
       "      <td>16.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.136900</td>\n",
       "      <td>2.824935</td>\n",
       "      <td>2.623600</td>\n",
       "      <td>16.880000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-5500\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-5500/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-5500/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-5500/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-4500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6000\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6000/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6000/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6000/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-5000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6500\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6500/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6500/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6500/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-5500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7000\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7000/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7000/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7000/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7500\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7500/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7500/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7500/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-6500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8000\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8000/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8000/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8000/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8500\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8500/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8500/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8500/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-7500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9000\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9000/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9000/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9000/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9500\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9500/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9500/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9500/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-8500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-10000\n",
      "Configuration saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-10000/config.json\n",
      "Model weights saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-10000/special_tokens_map.json\n",
      "Copy vocab file to XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-10000/spiece.model\n",
      "Deleting older checkpoint [XLdefgen-trans-de-to-en-train10k-bat2/checkpoint-9000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=2.1093772705078124, metrics={'train_runtime': 2082.3419, 'train_samples_per_second': 9.605, 'train_steps_per_second': 4.802, 'total_flos': 2101922535813120.0, 'train_loss': 2.1093772705078124, 'epoch': 2.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache() #to free up space\n",
    "# if wb:\n",
    "#   wandb.init(resume=True)\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "# if wb:\n",
    "#   wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-U-C97b1LkWO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.824934720993042,\n",
       " 'eval_bleu': 2.6236,\n",
       " 'eval_gen_len': 16.88,\n",
       " 'eval_runtime': 16.6286,\n",
       " 'eval_samples_per_second': 6.014,\n",
       " 'eval_steps_per_second': 3.007,\n",
       " 'epoch': 2.0,\n",
       " 'eval_perplexity': 16.8598}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RBwGyYrN084"
   },
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tr95bq5YMirp"
   },
   "source": [
    "Test model predictive capacity with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "fz827skL-FKy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37194, 20567,   288,  5413,   267,   336,  9070,   259, 42822,   514,\n",
      "          1037, 64712, 10990,     1]])\n",
      "tensor([[37194, 20567,   288,  5413,   267,   336,  9070,   259, 42822,   514,\n",
      "          1037, 64712, 10990,     1]])\n",
      "tensor([[37194, 20567,   288,  5413,   267,  4824, 65941,   259, 69474,   749,\n",
      "           326,  2786,   259,   263, 71632,   272, 59498, 13651,   522,     1]])\n",
      "tensor([[ 37194,  20567,    288,   5413,    267,   4824, 122540,    265,    281,\n",
      "            442,   4208,      1]])\n",
      "\n",
      "Greedy Output:\n",
      "The USA is in USA.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Beam Output:\n",
      "['It is in the USA.', 'It is in USA.', 'It is in the USA, in the USA.']\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(prefix + 'I enjoy walking with my cute dog', return_tensors='pt')\n",
    "print(input_ids)\n",
    "\n",
    "input_ids = tokenizer(prefix + 'I enjoy walking with my cute dog', return_tensors='pt').input_ids\n",
    "print(input_ids)\n",
    "\n",
    "input_ids = tokenizer(prefix + 'Ich gehe gern mit meinem süßen Hund Gassi', return_tensors='pt').input_ids\n",
    "print(input_ids)\n",
    "\n",
    "input_ids = tokenizer(prefix + \"Ich wohne in der USA\", return_tensors='pt').input_ids\n",
    "print(input_ids)\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "greedy_output = model.generate(input_ids)\n",
    "print(\"\\nGreedy Output:\")\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True, min_length=5))\n",
    "\n",
    "outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3)\n",
    "print(\"\\n\" + 100 * '-' + \"\\n\\nBeam Output:\")\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZGyR1ZG4u1r"
   },
   "source": [
    "Push Model to HF Model Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zZID0xEz4u1r"
   },
   "outputs": [],
   "source": [
    "# trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mt5_de-en_translation_2-5.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "14f3cr9x_NFH3ijBAiW8eX_4tXDSJtYLf",
     "timestamp": 1643210084469
    },
    {
     "file_id": "1jecC75oqiCXVSDCkOz_GOJlEhRx-c6Q_",
     "timestamp": 1642539157370
    },
    {
     "file_id": "1J3ttZqUQHCa4BwtdHuC2qDIZLJVnCsk0",
     "timestamp": 1642536077715
    },
    {
     "file_id": "https://github.com/huggingface/notebooks/blob/master/examples/translation.ipynb",
     "timestamp": 1642535483080
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
