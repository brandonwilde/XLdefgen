{"cells":[{"cell_type":"markdown","source":["## **Model Fine-tuning** (Notebook sourced from translation notebook [here](https://huggingface.co/docs/transformers/notebooks))"],"metadata":{"id":"WFA_cq0WEBWS"}},{"cell_type":"markdown","source":["Enable logging with Weights and Biases:"],"metadata":{"id":"-6zcdt7BpLJE"}},{"cell_type":"code","source":["wb = False\n","# model_checkpoint = \"google/mt5-small\""],"metadata":{"id":"jcuv1RmQpEt7","executionInfo":{"status":"ok","timestamp":1644000430663,"user_tz":300,"elapsed":291,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["import os\n","work_dir = os.getcwd()\n","if work_dir == '/content':\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  os.chdir('drive/MyDrive/github_repos/XLdefgen')"],"metadata":{"id":"P0kUE65nK_9p","executionInfo":{"status":"ok","timestamp":1644000431216,"user_tz":300,"elapsed":5,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X4cRE8IbIrIV"},"source":["If running this on Colab, uncomment the following cell to install requisite packages."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"MOsHUjgdIrIW","executionInfo":{"status":"ok","timestamp":1644000438374,"user_tz":300,"elapsed":7162,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9562f710-560a-4c87-e662-12110835b286"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.18.3)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.10)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.1.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.9)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.4.4)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2.3.2)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.4)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.26)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.11)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","git-lfs is already the newest version (2.3.4-1).\n","The following packages were automatically installed and are no longer required:\n","  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n","  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n","  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n","  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n","  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n","  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n","  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n","  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n","  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n","  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n","  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n","  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n","  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n","  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n","  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n","  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n","  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n","  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n","  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n","  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n","  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n","  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n","  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n","  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n","  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n","  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n","  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n","  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n","  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n","  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n","  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n","  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n","  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n","  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n","  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n","Use 'apt autoremove' to remove them.\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"]}],"source":["!pip install datasets transformers sacrebleu sentencepiece wandb\n","!apt install git-lfs"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"EmnzArcYCFS8","executionInfo":{"status":"ok","timestamp":1644000438375,"user_tz":300,"elapsed":28,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["if wb:\n","  import wandb\n","  wandb.login()\n","  %env WANDB_PROJECT=XLdefgen"]},{"cell_type":"markdown","metadata":{"id":"-JL5wd9Z4u1U"},"source":["If storing model on HF Model Hub, uncomment the following:"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"pIymjpij4u1V","executionInfo":{"status":"ok","timestamp":1644000438377,"user_tz":300,"elapsed":12,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["# from huggingface_hub import notebook_login\n","# notebook_login()"]},{"cell_type":"markdown","metadata":{"id":"HFASsisvIrIb"},"source":["A script version of this notebook to fine-tune the model in a distributed fashion using multiple GPUs or TPUs is available [here](https://github.com/huggingface/transformers/tree/master/examples/seq2seq)."]},{"cell_type":"markdown","metadata":{"id":"rEJBSTyZIrIb"},"source":["Specify model checkpoint to load (from HF Model Hub)\n"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"UlraLg9K4u1Y","executionInfo":{"status":"ok","timestamp":1644000438378,"user_tz":300,"elapsed":11,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["model_checkpoint = \"google/mt5-small\""]},{"cell_type":"markdown","metadata":{"id":"whPRbBNbIrIl"},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"IreSlFmlIrIm","executionInfo":{"status":"ok","timestamp":1644000447799,"user_tz":300,"elapsed":9432,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}},"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["7f4447550b1c46e0aeafad30e309cfb1","c398731e83874aa1a6ab6ea72f35c602","7d0fe49aab9a4ae8af8ad87b1fb8ccb9","d52797e2eb474d9985fc0a8268af596e","52cde1bd0226446da3fb8ba368e29e59","cdaf24691c6e48aabcd7af0fb8492b02","d84e2dc776484eac92566ea0fa5db619","2f5399c255784ffb81d120b7a2dd989a","49356465fb0845fcaabc483bf6e3b172","49ec8f3d64df40739c66f8a8be07eeae","4740cca0409d438c9375f4b422471771"]},"outputId":"98b15678-4538-476a-f5e8-c5d1db4a879f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Reusing dataset wmt16 (/root/.cache/huggingface/datasets/wmt16/de-en/1.0.0/9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f4447550b1c46e0aeafad30e309cfb1","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{}}],"source":["import datasets\n","from datasets import load_dataset, load_metric\n","\n","raw_datasets = load_dataset(\"wmt16\", \"de-en\")\n","metric = load_metric(\"sacrebleu\")"]},{"cell_type":"markdown","metadata":{"id":"WHUmphG3IrI3"},"source":["To get a sense of what the data looks like, the following function shows some examples picked randomly from the dataset."]},{"cell_type":"code","execution_count":38,"metadata":{"id":"i3j8APAoIrI3","executionInfo":{"status":"ok","timestamp":1644000447801,"user_tz":300,"elapsed":21,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["# import datasets\n","# import random\n","# import pandas as pd\n","# from IPython.display import display, HTML\n","\n","# def show_random_elements(dataset, num_examples=5):\n","#     assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","#     picks = []\n","#     for _ in range(num_examples):\n","#         pick = random.randint(0, len(dataset)-1)\n","#         while pick in picks:\n","#             pick = random.randint(0, len(dataset)-1)\n","#         picks.append(pick)\n","    \n","#     df = pd.DataFrame(dataset[picks])\n","#     for column, typ in dataset.features.items():\n","#         if isinstance(typ, datasets.ClassLabel):\n","#             df[column] = df[column].transform(lambda i: typ.names[i])\n","#     display(HTML(df.to_html()))"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"SZy5tRB_IrI7","executionInfo":{"status":"ok","timestamp":1644000447803,"user_tz":300,"elapsed":21,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["# show_random_elements(raw_datasets[\"train\"])"]},{"cell_type":"markdown","metadata":{"id":"jAWdqcUBIrJC"},"source":["Demonstration of the metric in use:"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"6XN1Rq0aIrJC","executionInfo":{"status":"ok","timestamp":1644000447804,"user_tz":300,"elapsed":20,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9530a4f-baa2-4cb3-b0eb-9bee07b44d0f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bp': 1.0,\n"," 'counts': [4, 2, 0, 0],\n"," 'precisions': [100.0, 100.0, 0.0, 0.0],\n"," 'ref_len': 4,\n"," 'score': 0.0,\n"," 'sys_len': 4,\n"," 'totals': [4, 2, 0, 0]}"]},"metadata":{},"execution_count":40}],"source":["fake_preds = [\"hello there\", \"general kenobi\"]\n","fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n","metric.compute(predictions=fake_preds, references=fake_labels)"]},{"cell_type":"markdown","metadata":{"id":"n9qywopnIrJH"},"source":["## Preprocessing the data"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"eXNLu_-nIrJI","executionInfo":{"status":"ok","timestamp":1644000457122,"user_tz":300,"elapsed":9333,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"82d8d88d-c7d3-4d34-dbae-04f10d8f8992"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n","Model config MT5Config {\n","  \"_name_or_path\": \"google/mt5-small\",\n","  \"architectures\": [\n","    \"MT5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 1024,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 8,\n","  \"num_heads\": 6,\n","  \"num_layers\": 8,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n","loading file https://huggingface.co/google/mt5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/37d0f67f084f8c5fc5589e0bba5ff3c6307af833bb0b7f4eb33fbfd8d4038a9d.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n","loading file https://huggingface.co/google/mt5-small/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/google/mt5-small/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/google/mt5-small/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/685ac0ca8568ec593a48b61b0a3c272beee9bc194a3c7241d15dcadb5f875e53.f76030f3ec1b96a8199b2593390c610e76ca8028ef3d24680000619ffb646276\n","loading file https://huggingface.co/google/mt5-small/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/6a9e52d6dd21568e37b65fc180ada927968e8f7124f0acd6efcaf90cd2e0f4bb.4b81e5d952ad810ca1de2b3e362b9a26a5cc77b4b75daf20caf69fb838751c32\n","loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n","Model config MT5Config {\n","  \"_name_or_path\": \"google/mt5-small\",\n","  \"architectures\": [\n","    \"MT5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 1024,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 8,\n","  \"num_heads\": 6,\n","  \"num_layers\": 8,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n","loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n","Model config MT5Config {\n","  \"_name_or_path\": \"google/mt5-small\",\n","  \"architectures\": [\n","    \"MT5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 1024,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 8,\n","  \"num_heads\": 6,\n","  \"num_layers\": 8,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n"]}],"source":["from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"2C0hcmp9IrJQ"},"source":["Model-specific tokenizer adaptations"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"zqn3ZeBl4u1k","executionInfo":{"status":"ok","timestamp":1644000457123,"user_tz":300,"elapsed":27,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2714d2e-ea32-49b2-cdd5-2b17971280a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs will include prefix!\n"]}],"source":["if \"t5\" in model_checkpoint:\n","    prefix = \"translate English to German: \"\n","    print(\"Inputs will include prefix!\")\n","else:\n","    prefix = \"\"\n","    print(\"Inputs will not include prefix!\")\n","\n","if \"mbart\" in model_checkpoint:\n","    tokenizer.src_lang = \"en-XX\"\n","    tokenizer.tgt_lang = \"de-DE\""]},{"cell_type":"markdown","source":["Create preprocessing function"],"metadata":{"id":"AzohepNVHEuL"}},{"cell_type":"code","execution_count":43,"metadata":{"id":"vc0BSBLIIrJQ","executionInfo":{"status":"ok","timestamp":1644000457125,"user_tz":300,"elapsed":26,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["max_input_length = 128\n","max_target_length = 128\n","source_lang = \"en\"\n","target_lang = \"de\"\n","\n","def preprocess_function(examples):\n","    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n","    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"markdown","source":["Specify whether reduced dataset should be passed to model"],"metadata":{"id":"s1xBe3UiHTkp"}},{"cell_type":"code","execution_count":61,"metadata":{"id":"Sii3lf3ThnPM","executionInfo":{"status":"ok","timestamp":1644000895925,"user_tz":300,"elapsed":859,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["trim_datasets = True\n","train_size = 10000\n","eval_size = 1000"]},{"cell_type":"markdown","source":["Preprocess data"],"metadata":{"id":"r8eOtIBLHgaB"}},{"cell_type":"code","execution_count":58,"metadata":{"id":"uAr_iWrLurIK","executionInfo":{"status":"ok","timestamp":1644000838864,"user_tz":300,"elapsed":13017,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}},"colab":{"base_uri":"https://localhost:8080/","height":142,"referenced_widgets":["6dd2c0506b33403cb7972126b0c47a92","522be1a3ce6c4a67b93854c515344ca7","cb1e13337ff148b599a5714d69e3f204","d3dc6bc10c134fdd9d3ff82098de19c5","7a68f47c28464b81842e5fa8ec130fe7","3b194164b0894a7ab73e658aa43ffeaf","376b33648572457c944ef206025b58b7","e23fd355c39c49af9ae8039e059d53fb","d6745b8200d24303bb33996cb335264e","0d11f298406a45528bfc6e09e1d28f40","be539017e5554b389b2f74dba494a128"]},"outputId":"7abd4054-4b11-4a46-eb61-927697194185"},"outputs":[{"output_type":"stream","name":"stderr","text":["Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/wmt16/de-en/1.0.0/9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0/cache-1ab007a7cd427b2e.arrow\n","Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/wmt16/de-en/1.0.0/9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0/cache-b8b8ca317d39cf50.arrow\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6dd2c0506b33403cb7972126b0c47a92","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/5 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/de-en/1.0.0/9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0/cache-c850482d96f61270.arrow\n"]},{"output_type":"stream","name":"stdout","text":["Datasets trimmed and tokenized.\n"]}],"source":["if trim_datasets:\n","  small_train_dataset = raw_datasets[\"train\"].shuffle(seed=42).select(range(train_size))\n","  small_eval_dataset = raw_datasets[\"validation\"].shuffle(seed=42).select(range(eval_size))\n","  raw_datasets_trim = datasets.DatasetDict({'train': small_train_dataset, 'validation': small_eval_dataset})\n","  tokenized_datasets = raw_datasets_trim.map(preprocess_function, batched=True)\n","  print(\"Datasets trimmed and tokenized.\")\n","else:\n","  tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n","  print(\"Raw datasets tokenized.\")"]},{"cell_type":"markdown","metadata":{"id":"voWiw8C7IrJV"},"source":["The results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). 🤗 Datasets warns you when it uses cached files, but you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again."]},{"cell_type":"markdown","metadata":{"id":"545PP3o8IrJV"},"source":["## Fine-tuning the model"]},{"cell_type":"markdown","metadata":{"id":"FBiW8UpKIrJW"},"source":["Now that our data is ready, we can download the pretrained model and fine-tune it. Since our task is of the sequence-to-sequence kind, we use the `AutoModelForSeq2SeqLM` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us."]},{"cell_type":"code","execution_count":46,"metadata":{"id":"TlqNaB8jIrJW","executionInfo":{"status":"ok","timestamp":1644000467870,"user_tz":300,"elapsed":9482,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0650e0e6-fbf0-4c42-dc93-d44b81264fda"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n","Model config MT5Config {\n","  \"_name_or_path\": \"google/mt5-small\",\n","  \"architectures\": [\n","    \"MT5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 1024,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 8,\n","  \"num_heads\": 6,\n","  \"num_layers\": 8,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n","loading weights file https://huggingface.co/google/mt5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8e7b2a80ddcb5611b27d8c89e1e8e33a947e105415051402a22b9c8d7d1caeb0.e22331f3a065b885b30ae3dd1ff11ccaf7fbc444485f6eb07ef5e0138bca8b70\n","All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n","\n","All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-small.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n"]}],"source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","import torch\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n"]},{"cell_type":"markdown","metadata":{"id":"_N8urzhyIrJY"},"source":["Specify batch size and training arguments"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"Bliy8zgjIrJY","executionInfo":{"status":"ok","timestamp":1644000679138,"user_tz":300,"elapsed":988,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"987aa8f0-2de5-4c21-952e-9fe99a9f3c4b"},"outputs":[{"output_type":"stream","name":"stderr","text":["using `logging_steps` to initialize `eval_steps` to 500\n","PyTorch: setting up devices\n"]}],"source":["batch_size = 8\n","model_name = model_checkpoint.split(\"/\")[-1]\n","if wb:\n","  report = \"wandb\"\n","else:\n","  report = \"none\"\n","args = Seq2SeqTrainingArguments(\n","    # f\"drive/MyDrive/{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n","    f\"XLdefgen-{source_lang}-to-{target_lang}\",\n","    # f\"XLdefgen-trans-{source_lang}-to-{target_lang}-train{train_size}-bat{batch_size}\", #output directory\n","    evaluation_strategy = \"steps\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=3, #max num of checkpoints to keep\n","    num_train_epochs=13,\n","    predict_with_generate=True,\n","    fp16=False,         #mixed precision (acceleration) - doesn't work well with t5 models\n","    push_to_hub=False,  #push to HF Model Hub\n","    report_to=report,   #for data logging\n","    ignore_data_skip=True,   #if true and loading from checkpoint, this will start at beginning of dataset rather than where left off\n","    load_best_model_at_end=True\n",")"]},{"cell_type":"markdown","source":["Add data collator to pad inputs and labels to max length for each batch"],"metadata":{"id":"3vtlfP4mLAtV"}},{"cell_type":"code","execution_count":48,"metadata":{"id":"-HycQdUC4u1o","executionInfo":{"status":"ok","timestamp":1644000467874,"user_tz":300,"elapsed":20,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"markdown","source":["Post-processing and compute metrics"],"metadata":{"id":"Ylg71wOsLYgv"}},{"cell_type":"code","execution_count":49,"metadata":{"id":"UmvbnJ9JIrJd","executionInfo":{"status":"ok","timestamp":1644000467875,"user_tz":300,"elapsed":21,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["import numpy as np\n","\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","    return preds, labels\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    result = {\"bleu\": result[\"score\"]}\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    result[\"perplexity\"] = torch.exp(model.loss) #Trying to report perplexity\n","\n","    result = {k: round(v, 4) for k, v in result.items()}\n","\n","    return result\n","\n","# def compute_metrics(eval_pred):\n","#     metric1 = load_metric(\"precision\")\n","#     metric2 = load_metric(\"recall\")\n","    \n","#     logits, labels = eval_pred\n","#     predictions = np.argmax(logits, axis=-1)\n","#     precision = metric1.compute(predictions=predictions, references=labels)[\"precision\"]\n","#     recall = metric2.compute(predictions=predictions, references=labels)[\"recall\"]\n","#     return {\"precision\": precision, \"recall\": recall}"]},{"cell_type":"markdown","metadata":{"id":"rXuFTAzDIrJe"},"source":["Instantiate Trainer"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"imY1oC3SIrJf","executionInfo":{"status":"ok","timestamp":1644000848981,"user_tz":300,"elapsed":301,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"markdown","metadata":{"id":"CdzABDVcIrJg"},"source":["Train/fine-tune the model"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"uNx5pyRlIrJh","scrolled":false,"executionInfo":{"status":"error","timestamp":1644000861941,"user_tz":300,"elapsed":8140,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}},"colab":{"base_uri":"https://localhost:8080/","height":524},"outputId":"857847ec-910c-4343-ffd1-74d9c6a2fb32"},"outputs":[{"output_type":"stream","name":"stderr","text":["Loading model from XLdefgen-en-to-de/checkpoint-15500).\n","The following columns in the training set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-b136a1a1f322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# if wb:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#   wandb.finish()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;31m# Check if saved optimizer or scheduler states exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_optimizer_and_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;31m# important: at this point:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_load_optimizer_and_scheduler\u001b[0;34m(self, checkpoint)\u001b[0m\n\u001b[1;32m   1752\u001b[0m                 \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m                 self.optimizer.load_state_dict(\n\u001b[0;32m-> 1754\u001b[0;31m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m                 )\n\u001b[1;32m   1756\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 11.17 GiB total capacity; 9.90 GiB already allocated; 111.81 MiB free; 10.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["torch.cuda.empty_cache() #to free up space\n","if wb:\n","  wandb.init(resume=True)\n","trainer.train(resume_from_checkpoint=True)\n","# if wb:\n","#   wandb.finish()"]},{"cell_type":"markdown","source":["## Model testing"],"metadata":{"id":"3RBwGyYrN084"}},{"cell_type":"markdown","source":["Test model predictive capacity with an example"],"metadata":{"id":"Tr95bq5YMirp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fz827skL-FKy","executionInfo":{"status":"aborted","timestamp":1644000468492,"user_tz":300,"elapsed":635,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["input_ids = tokenizer.encode(prefix + 'I enjoy walking with my cute dog', return_tensors='pt')\n","print(input_ids)\n","\n","input_ids = tokenizer(prefix + 'I enjoy walking with my cute dog', return_tensors='pt').input_ids\n","print(input_ids)\n","\n","input_ids = input_ids.to(device)\n","\n","greedy_output = model.generate(input_ids)\n","print(\"\\nGreedy Output:\")\n","print(tokenizer.decode(greedy_output[0], skip_special_tokens=True, min_length=5))\n","\n","outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3)\n","print(\"\\n\" + 100 * '-' + \"\\n\\nBeam Output:\")\n","print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"]},{"cell_type":"markdown","metadata":{"id":"EZGyR1ZG4u1r"},"source":["Push Model to HF Model Hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZID0xEz4u1r","executionInfo":{"status":"aborted","timestamp":1644000468494,"user_tz":300,"elapsed":635,"user":{"displayName":"Brandon Wilde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVczSsXsm7x6mp0Lr5GzIAsj6EDDkTgWlg_lg=s64","userId":"18127879461253566195"}}},"outputs":[],"source":["# trainer.push_to_hub()"]}],"metadata":{"accelerator":"GPU","colab":{"name":"mt5_de-en_translation_1-31","provenance":[{"file_id":"14f3cr9x_NFH3ijBAiW8eX_4tXDSJtYLf","timestamp":1643210084469},{"file_id":"1jecC75oqiCXVSDCkOz_GOJlEhRx-c6Q_","timestamp":1642539157370},{"file_id":"1J3ttZqUQHCa4BwtdHuC2qDIZLJVnCsk0","timestamp":1642536077715},{"file_id":"https://github.com/huggingface/notebooks/blob/master/examples/translation.ipynb","timestamp":1642535483080}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7f4447550b1c46e0aeafad30e309cfb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c398731e83874aa1a6ab6ea72f35c602","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7d0fe49aab9a4ae8af8ad87b1fb8ccb9","IPY_MODEL_d52797e2eb474d9985fc0a8268af596e","IPY_MODEL_52cde1bd0226446da3fb8ba368e29e59"]}},"c398731e83874aa1a6ab6ea72f35c602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d0fe49aab9a4ae8af8ad87b1fb8ccb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cdaf24691c6e48aabcd7af0fb8492b02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d84e2dc776484eac92566ea0fa5db619"}},"d52797e2eb474d9985fc0a8268af596e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2f5399c255784ffb81d120b7a2dd989a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_49356465fb0845fcaabc483bf6e3b172"}},"52cde1bd0226446da3fb8ba368e29e59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_49ec8f3d64df40739c66f8a8be07eeae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [00:03&lt;00:00,  3.58s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4740cca0409d438c9375f4b422471771"}},"cdaf24691c6e48aabcd7af0fb8492b02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d84e2dc776484eac92566ea0fa5db619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f5399c255784ffb81d120b7a2dd989a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"49356465fb0845fcaabc483bf6e3b172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49ec8f3d64df40739c66f8a8be07eeae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4740cca0409d438c9375f4b422471771":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6dd2c0506b33403cb7972126b0c47a92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_522be1a3ce6c4a67b93854c515344ca7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cb1e13337ff148b599a5714d69e3f204","IPY_MODEL_d3dc6bc10c134fdd9d3ff82098de19c5","IPY_MODEL_7a68f47c28464b81842e5fa8ec130fe7"]}},"522be1a3ce6c4a67b93854c515344ca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb1e13337ff148b599a5714d69e3f204":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3b194164b0894a7ab73e658aa43ffeaf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_376b33648572457c944ef206025b58b7"}},"d3dc6bc10c134fdd9d3ff82098de19c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e23fd355c39c49af9ae8039e059d53fb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":5,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d6745b8200d24303bb33996cb335264e"}},"7a68f47c28464b81842e5fa8ec130fe7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d11f298406a45528bfc6e09e1d28f40","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5/5 [00:12&lt;00:00,  1.80s/ba]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be539017e5554b389b2f74dba494a128"}},"3b194164b0894a7ab73e658aa43ffeaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"376b33648572457c944ef206025b58b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e23fd355c39c49af9ae8039e059d53fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d6745b8200d24303bb33996cb335264e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d11f298406a45528bfc6e09e1d28f40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"be539017e5554b389b2f74dba494a128":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}